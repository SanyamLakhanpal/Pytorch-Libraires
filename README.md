# Pytorch-Libraires
Pytorch Libraries for daily use-cases

- Pytorch Warmup : Learning Rate Warmup in PyTorch (URL: https://github.com/Tony-Y/pytorch_warmup)
- Torch view: visualize pytorch models (URL: https://github.com/mert-kurttutan/torchview)
- Torch Info: To get the information of the layers and the not of params. (URL: https://github.com/tyleryep/torchinfo)
- Timm: PyTorch image models, scripts, pretrained weights -- ResNet, ResNeXT, EfficientNet, EfficientNetV2, NFNet, Vision Transformer, MixNet, MobileNet-V3/V2, RegNet, DPN, CSPNet, and more (URL: https://github.com/huggingface/pytorch-image-models)
- Sentence Transformers: (This framework provides an easy method to compute dense vector representations for sentences, paragraphs, and images)
(URL: https://github.com/UKPLab/sentence-transformers/tree/master)
- Language Translation/detection
  - py-googletrans: For tranlation to different langauges: (URL: https://github.com/ssut/py-googletrans)
  - google trans: https://github.com/ShivangKakkar/googletrans
  - google_trans_new: https://github.com/lushan88a/google_trans_new
  - Lang. Detection: 
    - https://github.com/Mimino666/langdetect
    - https://github.com/zafercavdar/fasttext-langdetect
- Torch Ness: (Pytorch Tools, layers and encoder): Url: https://github.com/piteren/torchness
- Yonlu: Nice Expmples pytorch NLP: https://github.com/MinSong2/yonlu/tree/main
- Loop GPT: https://github.com/farizrahman4u/loopgpt ***
- Deep Lake: Dataset format is optimized for rapid streaming and querying of data while training models at scale (URL: https://github.com/activeloopai/deeplake/tree/main)
- Manifest: prompt Programmming: https://github.com/HazyResearch/manifest
- Quintus: https://github.com/rjmacarthy/quintus
- multidim-positional-encoding: An implementation of 1D, 2D, and 3D positional encoding in Pytorch and TensorFlow. (URL: https://github.com/tatp22/multidim-positional-encoding/tree/master)
- Rotary-embedding-torch: Implementation of Rotary Embeddings, from the Roformer paper, in Pytorch. (URL: https://github.com/lucidrains/rotary-embedding-torch)
- microsoft/unilm: Large-scale Self-supervised Pre-training Across Tasks, Languages, and Modalities (Docs: https://thegenerality.com/agi/ : URLhttps://github.com/microsoft/unilm) **
- pytorch-OpCounter: Count the MACs / FLOPs of your PyTorch model. (URL: https://github.com/Lyken17/pytorch-OpCounter/)
- vit-pytorch: Implementation of Vision Transformer, a simple way to achieve SOTA in vision classification with only a single transformer encoder, in Pytorch. (URL: https://github.com/lucidrains/vit-pytorch)
- PyTorch-NLP: Basic Utilities for PyTorch Natural Language Processing (NLP) :: More utilites avaialibe than torchtext (URL: https://github.com/PetrochukM/PyTorch-NLP)
- Antialiased-cnns: Improves the accuracy and stability of the CNN's: (URL: https://github.com/adobe/antialiased-cnns)
- SPlit Folders: Split folders with files (i.e. images) into training, validation and test (dataset) folders (URL: https://github.com/jfilter/split-folders)
- torchinfo / torchsummary: https://github.com/tyleryep/torchinfo
- AutoX: (AutoML library): https://github.com/4paradigm/AutoX/tree/master



