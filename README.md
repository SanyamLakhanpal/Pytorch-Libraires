# Pytorch-Libraires
Pytorch Libraries for daily use-cases

- Pytorch Warmup : Learning Rate Warmup in PyTorch (URL: https://github.com/Tony-Y/pytorch_warmup)
- Torch view: visualize pytorch models (URL: https://github.com/mert-kurttutan/torchview)
- Torch Info: To get the information of the layers and the not of params. (URL: https://github.com/tyleryep/torchinfo)
- Timm: PyTorch image models, scripts, pretrained weights -- ResNet, ResNeXT, EfficientNet, EfficientNetV2, NFNet, Vision Transformer, MixNet, MobileNet-V3/V2, RegNet, DPN, CSPNet, and more (URL: https://github.com/huggingface/pytorch-image-models)
- Sentence Transformers: (This framework provides an easy method to compute dense vector representations for sentences, paragraphs, and images)
(URL: https://github.com/UKPLab/sentence-transformers/tree/master)
- Language Translation/detection
  - py-googletrans: For tranlation to different langauges: (URL: https://github.com/ssut/py-googletrans)
  - google trans: https://github.com/ShivangKakkar/googletrans
  - google_trans_new: https://github.com/lushan88a/google_trans_new
  - Lang. Detection: 
    - https://github.com/Mimino666/langdetect
    - https://github.com/zafercavdar/fasttext-langdetect
- Torch Ness: (Pytorch Tools, layers and encoder): Url: https://github.com/piteren/torchness
- Yonlu: Nice Expmples pytorch NLP: https://github.com/MinSong2/yonlu/tree/main
- Loop GPT: https://github.com/farizrahman4u/loopgpt ***
- Deep Lake: Dataset format is optimized for rapid streaming and querying of data while training models at scale (URL: https://github.com/activeloopai/deeplake/tree/main)
- Manifest: prompt Programmming: https://github.com/HazyResearch/manifest
- Quintus: https://github.com/rjmacarthy/quintus
- multidim-positional-encoding: An implementation of 1D, 2D, and 3D positional encoding in Pytorch and TensorFlow. (URL: https://github.com/tatp22/multidim-positional-encoding/tree/master)
- Rotary-embedding-torch: Implementation of Rotary Embeddings, from the Roformer paper, in Pytorch. (URL: https://github.com/lucidrains/rotary-embedding-torch)
- microsoft/unilm: Large-scale Self-supervised Pre-training Across Tasks, Languages, and Modalities (Docs: https://thegenerality.com/agi/ : URLhttps://github.com/microsoft/unilm) **
- pytorch-OpCounter: Count the MACs / FLOPs of your PyTorch model. (URL: https://github.com/Lyken17/pytorch-OpCounter/)
- vit-pytorch: Implementation of Vision Transformer, a simple way to achieve SOTA in vision classification with only a single transformer encoder, in Pytorch. (URL: https://github.com/lucidrains/vit-pytorch)
- PyTorch-NLP: Basic Utilities for PyTorch Natural Language Processing (NLP) :: More utilites avaialibe than torchtext (URL: https://github.com/PetrochukM/PyTorch-NLP)
- Antialiased-cnns: Improves the accuracy and stability of the CNN's: (URL: https://github.com/adobe/antialiased-cnns)
- SPlit Folders: Split folders with files (i.e. images) into training, validation and test (dataset) folders (URL: https://github.com/jfilter/split-folders)
- torchinfo / torchsummary: https://github.com/tyleryep/torchinfo
- AutoX: (AutoML library): https://github.com/4paradigm/AutoX/tree/master
- Weight Watcher : (Library to monitor the weights of intermediate layers of DNN, debugging) [https://github.com/CalculatedContent/WeightWatcher]
- Sophia: Effortless plugin and play Optimizer to cut model training costs by 50%. New optimizer that is 2x faster than Adam on LLMs.  (https://github.com/kyegomez/Sophia)
- Deep Speed (microsoft): DeepSpeed is a deep learning optimization library that makes distributed training and inference easy, efficient, and effective. [https://github.com/microsoft/DeepSpeed] 
- ColossalAI: Colossal-AI provides a collection of parallel components for you. We aim to support you to write your distributed deep learning models just like how you write your model on your laptop. We provide user-friendly tools to kickstart distributed training and inference in a few lines. [https://github.com/hpcaitech/ColossalAI]
- FairScale: FairScale is a PyTorch extension library for high performance and large scale training. FairScale makes available the latest distributed training techniques in the form of composable modules and easy to use APIs.: [https://fairscale.readthedocs.io/en/latest/]
- Daft: Daft is a fast, Pythonic and scalable open-source dataframe library built for Python and Machine Learning workloads. [https://github.com/Eventual-Inc/Daft]
- Texar Pytorch: The tool is designed for both researchers and practitioners for fast prototyping and experimentation. [https://github.com/asyml/texar-pytorch]
- TabPFN: The TabPFN is a neural network that learned to do tabular data prediction. This is the original CUDA-supporting pytorch impelementation [https://github.com/automl/TabPFN]
- AutoPytorch: Automatic architecture search and hyperparameter optimization for PyTorch [https://github.com/automl/Auto-PyTorch]
- EasyNMT: Easy to use, state-of-the-art Neural Machine Translation for 100+ languages. Atleast better compared to py-google trasnlate. [https://github.com/UKPLab/EasyNMT]
- Google_trans_new: A free and unlimited python API for google translate. [https://github.com/lushan88a/google_trans_new]
- Google trans py: Google Translate Client with `deep-translator` [https://github.com/suqingdong/googletranslatepy]
- iterative-stratification: scikit-learn cross validators for iterative stratification of multilabel data [https://github.com/trent-b/iterative-stratification]
- Visuallayer ** (Simplify Your Visual Data Ops. Find and visualize issues with your computer vision datasets such as duplicates, anomalies, data leakage, mislabels and others.): [https://github.com/visual-layer/visuallayer]
- Fastdup ** (fastdup is a powerful free tool designed to rapidly extract valuable insights from your image & video datasets. Assisting you to increase your dataset images & labels quality and reduce your data operations costs at an unparalleled scale.): [https://github.com/visual-layer/fastdup]


