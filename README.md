# Pytorch-Libraries
Pytorch Libraries for daily use-cases

- Pytorch Warmup : Learning Rate Warmup in PyTorch (URL: https://github.com/Tony-Y/pytorch_warmup)
- Torch view: visualize pytorch models (URL: https://github.com/mert-kurttutan/torchview)
- Torch Info: To get the information of the layers and the not of params. (URL: https://github.com/tyleryep/torchinfo)
- Timm: PyTorch image models, scripts, pre-trained weights -- ResNet, ResNeXT, EfficientNet, EfficientNetV2, NFNet, Vision Transformer, MixNet, MobileNet-V3/V2, RegNet, DPN, CSPNet, and more (URL: https://github.com/huggingface/pytorch-image-models)
- Sentence Transformers: (This framework provides an easy method to compute dense vector representations for sentences, paragraphs, and images)
(URL: https://github.com/UKPLab/sentence-transformers/tree/master)
- Language Translation/detection
  - py-googletrans: For tranlation to different langauges: (URL: https://github.com/ssut/py-googletrans)
  - google trans: https://github.com/ShivangKakkar/googletrans
  - google_trans_new: https://github.com/lushan88a/google_trans_new
  - Lang. Detection: 
    - https://github.com/Mimino666/langdetect
    - https://github.com/zafercavdar/fasttext-langdetect
- Torch Ness: (Pytorch Tools, layers, and encoder): Url: https://github.com/piteren/torchness
- Yonlu: Nice Examples Pytorch NLP: https://github.com/MinSong2/yonlu/tree/main
- Loop GPT: https://github.com/farizrahman4u/loopgpt ***
- Deep Lake: Dataset format is optimized for rapid streaming and querying of data while training models at scale (URL: https://github.com/activeloopai/deeplake/tree/main)
- Manifest: prompt Programming: https://github.com/HazyResearch/manifest
- Quintus: https://github.com/rjmacarthy/quintus
- multidim-positional-encoding: An implementation of 1D, 2D, and 3D positional encoding in Pytorch and TensorFlow. (URL: https://github.com/tatp22/multidim-positional-encoding/tree/master)
- Rotary-embedding-torch: Implementation of Rotary Embeddings, from the Roformer paper, in Pytorch. (URL: https://github.com/lucidrains/rotary-embedding-torch)
- Microsoft/unilm: Large-scale Self-supervised Pre-training Across Tasks, Languages, and Modalities (Docs: https://thegenerality.com/agi/ : URLhttps://github.com/microsoft/unilm) **
- PyTorch-OpCounter: Count the MACs / FLOPs of your PyTorch model. (URL: https://github.com/Lyken17/pytorch-OpCounter/)
- vit-pytorch: Implementation of Vision Transformer, a simple way to achieve SOTA in vision classification with only a single transformer encoder, in Pytorch. (URL: https://github.com/lucidrains/vit-pytorch)
- PyTorch-NLP: Basic Utilities for PyTorch Natural Language Processing (NLP) :: More utilites avaialibe than torchtext (URL: https://github.com/PetrochukM/PyTorch-NLP)
- Antialiased-cnns: Improves the accuracy and stability of the CNNs: (URL: https://github.com/adobe/antialiased-cnns)
- Split Folders: Split folders with files (i.e. images) into training, validation, and test (dataset) folders (URL: https://github.com/jfilter/split-folders)
- torchinfo / torchsummary: https://github.com/tyleryep/torchinfo
- AutoX: (AutoML library): https://github.com/4paradigm/AutoX/tree/master
- Weight Watcher : (Library to monitor the weights of intermediate layers of DNN, debugging) [https://github.com/CalculatedContent/WeightWatcher]
- Sophia: Effortless plugin and play Optimizer to cut model training costs by 50%. New optimizer that is 2x faster than Adam on LLMs.  (https://github.com/kyegomez/Sophia)
- Deep Speed (Microsoft): DeepSpeed is a deep learning optimization library that makes distributed training and inference easy, efficient, and effective. [https://github.com/microsoft/DeepSpeed] 
- ColossalAI: Colossal-AI provides a collection of parallel components for you. We aim to support you to write your distributed deep learning models just like how you write your model on your laptop. We provide user-friendly tools to kickstart distributed training and inference in a few lines. [https://github.com/hpcaitech/ColossalAI]
- FairScale: FairScale is a PyTorch extension library for high-performance and large-scale training. FairScale makes available the latest distributed training techniques in the form of composable modules and easy-to-use APIs.: [https://fairscale.readthedocs.io/en/latest/]
- Daft: Daft is a fast, Pythonic, and scalable open-source data frame library built for Python and Machine Learning workloads. [https://github.com/Eventual-Inc/Daft]
- Texar Pytorch: The tool is designed for both researchers and practitioners for fast prototyping and experimentation. [https://github.com/asyml/texar-pytorch]
- TabPFN: The TabPFN is a neural network that is learned to predict tabular data. This is the original CUDA-supporting pytorch implementation [https://github.com/automl/TabPFN]
- AutoPytorch: Automatic architecture search and hyperparameter optimization for PyTorch [https://github.com/automl/Auto-PyTorch]
- EasyNMT: Easy to use, state-of-the-art Neural Machine Translation for 100+ languages. At least better compared to py-google trasnlate. [https://github.com/UKPLab/EasyNMT]
- Google_trans_new: A free and unlimited Python API for google translate. [https://github.com/lushan88a/google_trans_new]
- Google trans py: Google Translate Client with `deep-translator` [https://github.com/suqingdong/googletranslatepy]
- iterative-stratification: scikit-learn cross validators for iterative stratification of multilabel data [https://github.com/trent-b/iterative-stratification]
- Visual layer ** (Simplify Your Visual Data Ops. Find and visualize issues with your computer vision datasets such as duplicates, anomalies, data leakage, mislabels and others.): [https://github.com/visual-layer/visuallayer]
- Fastdup ** (fastdup is a powerful free tool designed to rapidly extract valuable insights from your image & video datasets. Assisting you to increase your dataset images & labels quality and reduce your data operations costs at an unparalleled scale.): [https://github.com/visual-layer/fastdup]
- ComfyUI (Nice UI for running stable diffusion projects): [https://github.com/comfyanonymous/ComfyUI]
- Simple Transformers (Easy Transformers for Classification, NER, QA, Language Modelling, Language Generation, T5, Multi-Modal, and Conversational AI): [https://github.com/ThilinaRajapakse/simpletransformers]
- Easy BERT (Super Easy BERT and NLP Tasks): [https://github.com/utterworks/fast-bert/tree/main]
- Clean Lab (The standard data-centric AI package for data quality and machine learning with messy, real-world data and labels.): [https://github.com/cleanlab/cleanlab]
- Deep Checks (Tests for Continuous Validation of ML Models & Data): [https://github.com/deepchecks/deepchecks]
- Pair Code Lit (NLP model/prediction debugging UI): [https://github.com/PAIR-code/lit]
- Pytesseract (A python wrapper for Google Tesseract OCR system): [https://github.com/madmaze/pytesseract]
- Multimodal Mixup Data Augmentation: [https://github.com/amazon-science/mix-generation]
- 


